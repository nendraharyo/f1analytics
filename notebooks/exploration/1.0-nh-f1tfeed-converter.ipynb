{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import requests as rq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=r'F:\\DataspellProjects\\IndonesiaReg\\Data\\f1-tfeed'\n",
    "# Read dictionary pkl file\n",
    "with open(dir+'\\session_data.pkl', 'rb') as fp:\n",
    "    sessions = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsessions=r'https://f1.tfeed.net/sessions/eng_sessions.js'\n",
    "\n",
    "x=rq.get(urlsessions)\n",
    "races=re.findall('(\\d{4}_\\D+)\\',',x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#season data to get combinations of drivers, teams, etc\n",
    "season_data=re.findall('new Array\\((.+)\\);',x.text.replace('\\n',''))\n",
    "season_data=pd.DataFrame(season_data[0].split('\\t'))\n",
    "season_data[0];season_data[0].apply(lambda x: re.sub('\\)?;.+Array\\(','',x))\n",
    "season_data[0];season_data[0].apply(lambda x: re.sub('//','',x))\n",
    "\n",
    "to_drop=season_data[season_data[0]=='']\n",
    "season_data[0]=season_data[0].drop(to_drop.index)\n",
    "season_data.dropna(inplace=True)\n",
    "season_data.reset_index(inplace=True,drop=True)\n",
    "season_data[0];season_data[0].str.replace(\"'\",\"\")\n",
    "season_data;season_data[0].str.split(',',expand=True).drop(columns=[5])\n",
    "season_data['season'];season_data[3].apply(lambda x: re.findall('(\\d{4})',x)[0])\n",
    "season_data.rename(columns={0:'weekend_num',1:'race_name',2:'session_name',3:'driver_set',4:'team_set'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getLapHistory(text):\n",
    "    firstlist=re.findall('sessionhistory\\[\\'.+\\'\\]',text.replace('\\n',''))[0].replace('sessionhistory','').split(';')\n",
    "    df_laps=pd.DataFrame(firstlist)\n",
    "    df_laps[0]=df_laps[0].str.replace('[\\[\\]\\']','',regex=True)\n",
    "    df_laps[['driver_name','data']]=df_laps[0].str.split('=',expand=True)\n",
    "\n",
    "    def getLaps(x):\n",
    "        lap=re.findall('\\d+',x)\n",
    "        if len(lap)>0:\n",
    "            return lap[0] \n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "    df_laps['lap']=df_laps['driver_name'].apply(lambda x: getLaps(x))\n",
    "    df_laps['driver_name']=df_laps['driver_name'].str.replace('\\d+','',regex=True)\n",
    "    df_laps[['position','laptime','gap_fr_leader','interval','best_time','pits','status','pitstatus','res1','res2','res3','sector1','sector2','sector3','driver_infront']]=df_laps['data'].str.split(',',expand=True)\n",
    "    df_laps=df_laps.drop([0,'data'],axis=1)\n",
    "    df_laps=df_laps.dropna(subset='laptime').reset_index(drop=True)\n",
    "    int_cols=['lap','position','best_time','pits','status','pitstatus','res1','res2','res3']\n",
    "    float_cols=['laptime','gap_fr_leader','interval','sector1','sector2','sector3']\n",
    "    for cols in int_cols:\n",
    "        df_laps[cols]=df_laps[cols].astype(int)\n",
    "    for cols in float_cols:\n",
    "        df_laps[cols]=df_laps[cols].astype(float)\n",
    "    df_laps['best_time']=df_laps['best_time'].apply(lambda x:hex(x))\n",
    "    return df_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=r'F:\\DataspellProjects\\IndonesiaReg\\Data\\f1-tfeed'\n",
    "# Read dictionary pkl file\n",
    "with open(dir+r'\\drivers_data.pkl', 'rb') as fp:\n",
    "    drivers = pickle.load(fp)\n",
    "with open(dir+r'\\team_data.pkl', 'rb') as fp:\n",
    "    teams = pickle.load(fp)\n",
    "    \n",
    "def getTeamsandDriver(teamset=None,driverset=None):\n",
    "    global drivers\n",
    "    global teams\n",
    "    \n",
    "    if driverset!=None:\n",
    "        driver_name=re.findall(\"drivers\\['(.+)'\\]\",drivers[driverset])\n",
    "        drivers_data=re.findall(\"Array\\((.+)\\);\",drivers[driverset])\n",
    "        drivers_dict=dict(zip(driver_name,drivers_data))\n",
    "        \n",
    "        \n",
    "        drivers_df=pd.DataFrame(pd.Series(drivers_dict)).reset_index()\n",
    "    \n",
    "        if len(re.findall(',',drivers_df[0][0]))<3:\n",
    "        \n",
    "            drivers_df[['driver_id','last_name','abbreviation']]=drivers_df[0].str.replace(\"'\",'').str.split(',',expand=True)\n",
    "            drivers_df['team_name']=None\n",
    "        else:\n",
    "            drivers_df[['driver_id','last_name','abbreviation','team_name']]=drivers_df[0].str.replace(\"'\",'').str.split(',',expand=True)\n",
    "        \n",
    "        drivers_df.drop(columns=0,inplace=True)\n",
    "        \n",
    "        drivers_df.rename(columns={'index':'driver_name'},inplace=True)\n",
    "        \n",
    "\n",
    "    if teamset!=None:\n",
    "        team_name=re.findall('teams\\[\"(.+)\"\\]',teams[teamset])\n",
    "        team_data=re.findall(\"Array\\((.+)\\);\",teams[teamset])\n",
    "        teams_dict=dict(zip(team_name,team_data))\n",
    "        teams_df=pd.DataFrame(pd.Series(teams_dict)).reset_index()\n",
    "        teams_df[0]=teams_df[0].str.replace('\\'#','\"#').str.replace('\\',','\",').str.replace('\\'','\"')\n",
    "        sanityCheck=max(teams_df[0].apply(lambda x: len(re.findall('\"#',x))))\n",
    "\n",
    "        if sanityCheck==2:\n",
    "            teams_df[['team_name','primary_color','secondary_color']]=teams_df[0].str.replace(\"'\",'').str.split(',',expand=True)\n",
    "        elif sanityCheck==3:\n",
    "            teams_df[['team_name','primary_color','secondary_color','third_color']]=teams_df[0].str.replace(\"'\",'').str.split(',',expand=True)\n",
    "        else:\n",
    "            teams_df[['team_name','primary_color','secondary_color','third_color','fourth_color']]=teams_df[0].str.replace(\"'\",'').str.split(',',expand=True)\n",
    "        teams_df.drop(columns=0,inplace=True)\n",
    "        teams_df.rename(columns={'index':'team'},inplace=True)\n",
    "\n",
    "        return (teams_df,drivers_df)\n",
    "    else:\n",
    "        return(drivers_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict={\n",
    "    0:'weather_state',\n",
    "    1:'track_temp',\n",
    "    2:'air_temp',\n",
    "    3:'humidity',\n",
    "    4:'wind_dir',\n",
    "    5:'wind_speed',\n",
    "    6:'air_pressure'  \n",
    "    }\n",
    "race_dict={\n",
    "    0:'flag_status',\n",
    "    1:'race_type',\n",
    "    2:'time_remaining_in_s',\n",
    "    3:'timestamp'\n",
    "    }\n",
    "\n",
    "def tyresetFix(datalist):\n",
    "        if datalist!=[]:\n",
    "            data=datalist[-1]\n",
    "            return data\n",
    "        else:\n",
    "            return [None,None]\n",
    "\n",
    "def convert_ntt(text,race_drivers):\n",
    "\n",
    "    tlmy_df_raw=json.loads(text.replace('ntt_f(','[').replace(');',']'))\n",
    "    \n",
    "    ver=tlmy_df_raw[0]\n",
    "    timestamp=tlmy_df_raw[1]\n",
    "    race_data=tlmy_df_raw[2]\n",
    "    weather_data=tlmy_df_raw[3]\n",
    "    telemetry_data=tlmy_df_raw[4]\n",
    "    if len(tlmy_df_raw)==6:\n",
    "        race_drivers=tlmy_df_raw[5]\n",
    "\n",
    "    telemetry_dict={\n",
    "    'index':'driver_num',\n",
    "    0:'status',\n",
    "    1:'laps',\n",
    "    2:'laptime',\n",
    "    3:'position',\n",
    "    4:'gap_from_leader',\n",
    "    5:'interval',\n",
    "    6:'pits',\n",
    "    7:'is_best',\n",
    "    8:'speed',\n",
    "    9:'gear',\n",
    "    10:'gear_switches',\n",
    "    11:'drs',\n",
    "    12:'lap_pos',\n",
    "    13:'engine_rpm',\n",
    "    14:'tyreset',\n",
    "    15:'speedtraps',\n",
    "    16:'maxspeedtraps',\n",
    "    17:'sector1',\n",
    "    18:'sector2',\n",
    "    19:'sector3',\n",
    "    }\n",
    "    if ver>=9:\n",
    "        telemetry_dict[20]='best_times'\n",
    "   \n",
    "    if ver>=10:\n",
    "        telemetry_dict[21]='sector_segments'\n",
    "        \n",
    "    if ver>=11:\n",
    "        telemetry_dict[22]='throttle'\n",
    "        telemetry_dict[23]='brake'\n",
    "    \n",
    "    tlmy_df=pd.DataFrame(dict(zip(race_drivers,telemetry_data))).transpose().reset_index().rename(columns=telemetry_dict)\n",
    "    tlmy_df['timestamp']=timestamp\n",
    "    cols=tlmy_df.columns\n",
    "    if 'tyreset' in cols:\n",
    "        tyreset_latest=tlmy_df['tyreset'].apply(lambda x:tyresetFix(x))\n",
    "        tlmy_df[['tyre_type','tyre_age']] = pd.DataFrame(tyreset_latest.tolist(),index=tlmy_df.index)\n",
    "    \n",
    "    if 'speedtraps' in cols:\n",
    "        \n",
    "        tlmy_df[['speedtraps1','speedtraps2','speedtraps3','speedtraps4']]=pd.DataFrame(tlmy_df['speedtraps'].tolist(),index=tlmy_df.index)\n",
    "                \n",
    "        \n",
    "        tlmy_df[['maxspeedtraps1','maxspeedtraps2','maxspeedtraps3','maxspeedtraps4']]=pd.DataFrame(tlmy_df['maxspeedtraps'].tolist(),index=tlmy_df.index)\n",
    "    if 'best_times' in cols:\n",
    "        \n",
    "        tlmy_df[['bts1','bts2','bts3','btlap']]=pd.DataFrame(tlmy_df['best_times'].tolist(),index=tlmy_df.index)\n",
    "    \n",
    "    if 'sector_segments' in cols:\n",
    "        \n",
    "        tlmy_df[['ss_s1','ss_s2','ss_s3']]=pd.DataFrame(tlmy_df['sector_segments'].tolist(),index=tlmy_df.index)\n",
    "\n",
    "    global weather_dict\n",
    "    global race_dict\n",
    "    \n",
    "    weather_df=pd.DataFrame(weather_data).transpose().rename(columns=weather_dict)\n",
    "    weather_df['timestamp']=timestamp\n",
    "\n",
    "    \n",
    "    race_df=pd.DataFrame(race_data).transpose().rename(columns=race_dict)\n",
    "    race_df['timestamp']=timestamp\n",
    "\n",
    "    return(tlmy_df,weather_df,race_df)\n",
    "\n",
    "def convert_timetable(text):\n",
    "    ver=re.findall(\"\\['ver'\\]=(\\d+)\",text)\n",
    "    if len(ver)>0:\n",
    "        ver=int(ver[0])\n",
    "    else:\n",
    "        ver=1\n",
    "    global weather_dict\n",
    "    global race_dict\n",
    "    \n",
    "    timestamp=re.findall(\"\\['timestamp'\\]=(\\d+)\",text)\n",
    "    flag_status=re.findall(\"\\['flag'\\]=(\\d+)\",text)\n",
    "    race_type=re.findall(\"\\['type'\\]=(\\d+)\",text)\n",
    "    time_remaining_in_s=re.findall(\"\\['remaining'\\]=(\\d+)\",text)\n",
    "\n",
    "    race_df=pd.DataFrame([flag_status,race_type,time_remaining_in_s,timestamp]).transpose().rename(columns=race_dict)\n",
    "    if len(re.findall(\"\\['weather'\\]=(\\d+)\",text))>0:\n",
    "        weather_df=pd.DataFrame(re.findall(\"\\['weather'\\]=(\\d+)\",text)).rename(columns=weather_dict)\n",
    "        weather_df['timestamp']=timestamp\n",
    "    else:\n",
    "        weather_df=pd.DataFrame(columns=weather_dict.values(),index=[0])\n",
    "    \n",
    "    telemetry_dict={\n",
    "    0:'timestamp',\n",
    "    1:'status',\n",
    "    2:'laps',\n",
    "    3:'laptime',\n",
    "    4:'position',\n",
    "    5:'gap_from_leader',\n",
    "    6:'interval',\n",
    "    7:'pits',\n",
    "    8:'is_best',\n",
    "    9:'sector1',\n",
    "    10:'sector2',\n",
    "    11:'sector3'\n",
    "    }\n",
    "    if ver>=2:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[9+i] = telemetry_dict.pop(8+i)\n",
    "        telemetry_dict[9]='driver_num'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "        \n",
    "    if ver>=3:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[14+i] = telemetry_dict.pop(9+i)\n",
    "        telemetry_dict[10]='speed'\n",
    "        telemetry_dict[11]='gear'\n",
    "        telemetry_dict[12]='lat'\n",
    "        telemetry_dict[13]='lon'\n",
    "        telemetry_dict[14]='lap_pos'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "        \n",
    "    if ver>=4:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[15+i] = telemetry_dict.pop(14+i)\n",
    "        telemetry_dict[15]='engine_rpm'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "    if ver>=5:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[17+i] = telemetry_dict.pop(15+i)\n",
    "        telemetry_dict[16]='tyre_type'\n",
    "        telemetry_dict[17]='tyre_age'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "    if ver>=6:\n",
    "        telemetry_dict[12]='gear_switches'\n",
    "        telemetry_dict[13]='drs'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "    if ver>=7:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[18+i] = telemetry_dict.pop(17+i)\n",
    "        telemetry_dict[16]='tyreset'\n",
    "        telemetry_dict[17]='start_pos'\n",
    "        telemetry_dict[18]='points'\n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "    if ver>=8:\n",
    "        for i in reversed(range(1,4)):\n",
    "            telemetry_dict[20+i] = telemetry_dict.pop(18+i)\n",
    "        telemetry_dict[19]='speedtraps'\n",
    "        telemetry_dict[20]='maxspeedtraps' \n",
    "        telemetry_dict=dict(sorted(telemetry_dict.items()))\n",
    "    \n",
    "    driver_names=re.findall(\"timetable\\['(.+)'\\]=new Array.+\",text)\n",
    "    if len(driver_names)>0:\n",
    "        telemetry_data=[json.loads(data.replace('(','[').replace(')',']')) for data in re.findall(\"timetable\\['.+'\\]=new Array(.+);\",text)]\n",
    "        tlmy_df=pd.DataFrame(dict(zip(driver_names,telemetry_data))).transpose()\n",
    "        tlmy_df=tlmy_df.rename(columns=telemetry_dict)\n",
    "        tlmy_df.reset_index(inplace=True)\n",
    "        tlmy_df.rename(columns={'index':'driver_name'},inplace=True)\n",
    "        if int(tlmy_df['timestamp'][0])==0:\n",
    "            tlmy_df['timestamp']=int(timestamp[0])\n",
    "    else:\n",
    "        tlmy_df=pd.DataFrame(columns=telemetry_dict.values(),index=[0])\n",
    "        tlmy_df['timestamp']=timestamp\n",
    "\n",
    "    if 'tyreset' in tlmy_df.columns:\n",
    "        tyreset_latest=tlmy_df['tyreset'].apply(lambda x:tyresetFix(x))\n",
    "        tlmy_df[['tyre_type','tyre_age']] = pd.DataFrame(tyreset_latest.tolist(),index=tlmy_df.index)\n",
    "    return(tlmy_df,weather_df,race_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start decoding 2022_suzuka...\n",
      "2022_suzuka is done\n",
      "start decoding 2022_austin...\n",
      "2022_austin is done\n",
      "start decoding 2022_mexico...\n",
      "2022_mexico is done\n",
      "start decoding 2022_brazil...\n",
      "2022_brazil is done\n",
      "start decoding 2022_abu_dhabi...\n",
      "2022_abu_dhabi is done\n",
      "start decoding 2023_bahrain...\n",
      "2023_bahrain is done\n",
      "start decoding 2023_saudi_arabia...\n",
      "2023_saudi_arabia is done\n",
      "start decoding 2023_australia...\n",
      "2023_australia is done\n",
      "start decoding 2023_baku...\n",
      "2023_baku is done\n",
      "start decoding 2023_miami...\n",
      "2023_miami is done\n",
      "start decoding 2023_monaco...\n",
      "2023_monaco is done\n",
      "start decoding 2023_spain...\n",
      "2023_spain is done\n",
      "start decoding 2023_canada...\n",
      "2023_canada is done\n",
      "start decoding 2023_spielberg...\n",
      "2023_spielberg is done\n",
      "start decoding 2023_silverstone...\n",
      "2023_silverstone is done\n",
      "start decoding 2023_hungary...\n",
      "2023_hungary is done\n",
      "start decoding 2023_spa...\n",
      "2023_spa is done\n",
      "start decoding 2023_zandvoort...\n",
      "2023_zandvoort is done\n",
      "start decoding 2023_monza...\n",
      "2023_monza is done\n",
      "start decoding 2023_singapore...\n",
      "2023_singapore is done\n",
      "start decoding 2023_suzuka...\n",
      "2023_suzuka is done\n",
      "start decoding 2023_qatar...\n",
      "2023_qatar is done\n",
      "start decoding 2023_austin...\n",
      "2023_austin is done\n",
      "start decoding 2023_mexico...\n",
      "2023_mexico is done\n",
      "start decoding 2023_brazil...\n",
      "2023_brazil is done\n",
      "start decoding 2023_las_vegas...\n",
      "2023_las_vegas is done\n",
      "start decoding 2023_abu_dhabi...\n",
      "2023_abu_dhabi is done\n",
      "start decoding 2024_bahrain...\n",
      "2024_bahrain is done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in season_data.itertuples():\n",
    "    if row[0]<258:\n",
    "        continue\n",
    "    if row[0] in [230,268,217]:\n",
    "        continue\n",
    "    session_name=row[3]\n",
    "    if session_name=='2024_saudi_arabia':\n",
    "        break\n",
    "    session_name=row[3]\n",
    "    driver_set=row[4]\n",
    "    team_set=row[5]\n",
    "    nttFlag=False\n",
    "\n",
    "    if team_set!='':\n",
    "        teams_df,driver_df=getTeamsandDriver(team_set,driver_set)\n",
    "        teams_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'teams_racing.csv'),index=False)\n",
    "    else:\n",
    "        driver_df=getTeamsandDriver(driverset=driver_set)\n",
    "    driver_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'drivers_racing.csv'),index=False)\n",
    "\n",
    "    state_js=re.findall('(state_.+js)',sessions[session_name])\n",
    "    #if len(re.findall('sessionlaps',sessions[session_name]))>0:\n",
    "    #    session_laps=re.findall('sessionlaps=new Array\\((.+)\\)\\;var',sessions[session_name].replace('\\n',''))[0].split(',')\n",
    "    #    zipped_states=pd.DataFramedict(zip(state_js,session_laps))\n",
    "\n",
    "\n",
    "    tlmy_full_df=pd.DataFrame()\n",
    "    weather_full_df=pd.DataFrame()\n",
    "    race_full_df=pd.DataFrame()\n",
    "    print('start decoding '+session_name+'...')\n",
    "    for file in os.listdir(r'../Data/f1-tfeed/{}/'.format(session_name)):\n",
    "        \n",
    "        if file.endswith('js'):\n",
    "            with open(r'../Data/f1-tfeed/{}/{}'.format(session_name,file),'rb') as jsfile:\n",
    "                text=jsfile.read().decode()\n",
    "            if len(text)==0:\n",
    "                continue\n",
    "        \n",
    "            if 'timetable' in text:\n",
    "                tlmy_df,weather_df,race_df=convert_timetable(text)\n",
    "            else:\n",
    "                if not nttFlag:\n",
    "                    nttFlag=True\n",
    "                    ndd_df=pd.DataFrame(json.loads(re.findall('ndd_f\\((.+)\\);',sessions[session_name])[0].replace(\"'\",\"\\\"\")))\n",
    "                    ndd_df.rename(columns={2:'starting_position',0:'driver_name',1:'driver_num',3:'pts_accumulated'},inplace=True)\n",
    "                    lapHist_df=getLapHistory(sessions[session_name])\n",
    "        \n",
    "                    lapHist_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'per_lap_history.csv'),index=False)\n",
    "                    ndd_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'driver_details_this_racing.csv'),index=False)\n",
    "                tlmy_df,weather_df,race_df=convert_ntt(text,ndd_df['driver_num'].to_list())\n",
    "                \n",
    "            #print(session_name+' '+file+' done')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        tlmy_full_df=pd.concat([tlmy_full_df,tlmy_df])\n",
    "        weather_full_df=pd.concat([weather_full_df,weather_df])\n",
    "        race_full_df=pd.concat([race_full_df,race_df])\n",
    "\n",
    "    \n",
    "    \n",
    "    tlmy_full_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'telemetry_data.csv'),index=False)\n",
    "    weather_full_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'weather_data.csv'),index=False)\n",
    "    race_full_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'racing_info.csv'),index=False)\n",
    "    \n",
    "    print(session_name+' is done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyre_type_dict={\n",
    "    0:'Undefined',\n",
    "\t1:'SuperSoft',\n",
    "\t2:'Soft',\n",
    "\t3:'Medium',\n",
    "\t4:'Hard',\n",
    "\t5:'Intermediate',\n",
    "\t6:'Wet',\n",
    "\t7:'Ultrasoft',\n",
    "\t8:'Hypersoft',\n",
    "\t9:'Soft2019',\n",
    "\t10:'Medium2019',\n",
    "\t11:'Hard2019',\n",
    "\t12:'Test'\n",
    "}\n",
    "\n",
    "track_status_dict={\n",
    "1:'FlagGreen',\n",
    "2:'FlagYellow',\n",
    "3:'SCStandBy',\n",
    "4:'SCDeployed',\n",
    "5:'FlagRed',\n",
    "6:'FlagChequered',\n",
    "7:'VSC'\n",
    "}\n",
    "\n",
    "session_type_dict={\n",
    "1:'Race',\n",
    "2:'Practice',\n",
    "3:'Qualification',\n",
    "4:'SprintQualification'\n",
    "}\n",
    "\n",
    "driver_status_dict={\n",
    "0:'OnTrack',\n",
    "1:'PitIn',\n",
    "2:'PitOut',\n",
    "3:'Finished',\n",
    "4:'Stopped'\n",
    "}\n",
    "\n",
    "drs_status_dict={\n",
    "\t0:'drs_off',\n",
    "\t1:'drs_standby',\n",
    "\t2:'drs_on'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine=create_engine(r'postgresql://wardoge:Roxassora1@192.168.1.66:5432/stbdb')\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(drs_status_dict,index=[0]).transpose().reset_index().rename(columns={'index':'code',0:'status'}).to_sql('drs_status',conn,if_exists='replace',index=False)\n",
    "pd.DataFrame(driver_status_dict,index=[0]).transpose().reset_index().rename(columns={'index':'code',0:'status'}).to_sql('driver_status',conn,if_exists='replace',index=False)\n",
    "pd.DataFrame(session_type_dict,index=[0]).transpose().reset_index().rename(columns={'index':'code',0:'status'}).to_sql('drs_status',conn,if_exists='replace',index=False)\n",
    "pd.DataFrame(track_status_dict,index=[0]).transpose().reset_index().rename(columns={'index':'code',0:'status'}).to_sql('track_status',conn,if_exists='replace',index=False)\n",
    "pd.DataFrame(tyre_type_dict,index=[0]).transpose().reset_index().rename(columns={'index':'code',0:'status'}).to_sql('tyre_type',conn,if_exists='replace',index=False)\n",
    "\n",
    "season_data.to_sql('season_data',conn,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "dir=r'F:\\DataspellProjects\\IndonesiaReg\\Data\\f1-tfeed'\n",
    "with open(dir+r'\\drivers_data.pkl', 'wb') as fp:\n",
    "    pickle.dump(drivers, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in season_data.itertuples():\n",
    "    if row[0]<258:\n",
    "        continue\n",
    "    if row[0] in [230,268,217]:\n",
    "        continue\n",
    "    session_name=row[3]\n",
    "    if session_name=='2024_saudi_arabia':\n",
    "        break\n",
    "    session_name=row[3]\n",
    "    driver_set=row[4]\n",
    "    team_set=row[5]\n",
    "    nttFlag=False\n",
    "\n",
    "    if team_set!='':\n",
    "        teams_df,driver_df=getTeamsandDriver(team_set,driver_set)\n",
    "        teams_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'teams_racing.csv'),index=False)\n",
    "    else:\n",
    "        driver_df=getTeamsandDriver(driverset=driver_set)\n",
    "    driver_df.to_csv(r'../Data/f1-tfeed/{}/{}'.format(session_name,'drivers_racing.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndonesiaReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
